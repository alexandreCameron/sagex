{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-to-join-and-merge-with-the-pandas-package\" data-toc-modified-id=\"Introduction-to-join-and-merge-with-the-pandas-package-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction to join and merge with the pandas package</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#This-tutorial-is-copied-from:\" data-toc-modified-id=\"This-tutorial-is-copied-from:-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>This tutorial is copied from:</a></span></li><li><span><a href=\"#Additionnal-information-can-be-found-at:\" data-toc-modified-id=\"Additionnal-information-can-be-found-at:-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Additionnal information can be found at:</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Purpose</a></span></li></ul></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Create-dummy-dataframe\" data-toc-modified-id=\"Create-dummy-dataframe-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Create dummy dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-first-dummy-dataframe-df_a\" data-toc-modified-id=\"Create-a-first-dummy-dataframe-df_a-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Create a first dummy dataframe <code>df_a</code></a></span></li><li><span><a href=\"#Create-a-second-dummy-dataframe-df_b\" data-toc-modified-id=\"Create-a-second-dummy-dataframe-df_b-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Create a second dummy dataframe <code>df_b</code></a></span></li><li><span><a href=\"#Create-a-third-dummy-dataframe-df_n\" data-toc-modified-id=\"Create-a-third-dummy-dataframe-df_n-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Create a third dummy dataframe <code>df_n</code></a></span></li></ul></li><li><span><a href=\"#Join\" data-toc-modified-id=\"Join-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Join</a></span><ul class=\"toc-item\"><li><span><a href=\"#Join-df_a-and-df_b-along-raws\" data-toc-modified-id=\"Join-df_a-and-df_b-along-raws-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Join <code>df_a</code> and <code>df_b</code> along raws</a></span></li><li><span><a href=\"#Join-df_a-and-df_b-along-columns\" data-toc-modified-id=\"Join-df_a-and-df_b-along-columns-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Join <code>df_a</code> and <code>df_b</code> along columns</a></span></li></ul></li><li><span><a href=\"#Merge\" data-toc-modified-id=\"Merge-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Merge</a></span><ul class=\"toc-item\"><li><span><a href=\"#Merge-dataframes-df_new,-df_n-using-the-subject_id-column\" data-toc-modified-id=\"Merge-dataframes-df_new,-df_n-using-the-subject_id-column-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Merge dataframes <code>df_new</code>, <code>df_n</code> using the subject_id column</a></span></li><li><span><a href=\"#Merge-two-dataframes-with-the-left-on-subject_id-and-the-right-on-subject_id\" data-toc-modified-id=\"Merge-two-dataframes-with-the-left-on-subject_id-and-the-right-on-subject_id-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Merge two dataframes with the left on subject_id and the right on subject_id</a></span></li><li><span><a href=\"#Merge-with-outer-join\" data-toc-modified-id=\"Merge-with-outer-join-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Merge with outer join</a></span></li><li><span><a href=\"#Merge-with-inner-join\" data-toc-modified-id=\"Merge-with-inner-join-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Merge with inner join</a></span></li><li><span><a href=\"#Merge-with-right-join\" data-toc-modified-id=\"Merge-with-right-join-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span>Merge with right join</a></span></li><li><span><a href=\"#Merge-with-left-join\" data-toc-modified-id=\"Merge-with-left-join-1.4.6\"><span class=\"toc-item-num\">1.4.6&nbsp;&nbsp;</span>Merge with left join</a></span></li><li><span><a href=\"#Merge-while-adding-a-suffix-to-duplicate-column-names\" data-toc-modified-id=\"Merge-while-adding-a-suffix-to-duplicate-column-names-1.4.7\"><span class=\"toc-item-num\">1.4.7&nbsp;&nbsp;</span>Merge while adding a suffix to duplicate column names</a></span></li><li><span><a href=\"#Merge-based-on-indexes\" data-toc-modified-id=\"Merge-based-on-indexes-1.4.8\"><span class=\"toc-item-num\">1.4.8&nbsp;&nbsp;</span>Merge based on indexes</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exercise</a></span><ul class=\"toc-item\"><li><span><a href=\"#Warning\" data-toc-modified-id=\"Warning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Warning</a></span></li><li><span><a href=\"#Hint\" data-toc-modified-id=\"Hint-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Hint</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to join and merge with the pandas package\n",
    "\n",
    "### This tutorial is copied from:\n",
    "\n",
    "1. https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "\n",
    "### Additionnal information can be found at:\n",
    "\n",
    "1. https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/\n",
    "2. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This tutorial will show how to use functionalities of the `pandas` package to merge and join table \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "The pandas package must be installed on your machine in order to use it.\n",
    "\n",
    "More information on the `pandas` package can be found:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/getting_started/index.html\n",
    "\n",
    "The `pandas` community is really active on stackoverflow:\n",
    "\n",
    "https://stackoverflow.com/\n",
    "\n",
    "Many of you question are probably answered on this website.\n",
    "\n",
    "***\n",
    "\n",
    "To import the `pandas` package, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T11:27:39.012599Z",
     "start_time": "2019-02-18T11:27:38.817254Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:14:39.366713Z",
     "start_time": "2019-02-18T10:14:39.356732Z"
    }
   },
   "source": [
    "### Create a first dummy dataframe `df_a`\n",
    "`df_a` has three columns (subject_id, first_name, last_name) corresponding to the ID of a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:18.075989Z",
     "start_time": "2019-02-18T10:40:18.048081Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': [1, 2, 3, 4, 5],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "df_a = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a second dummy dataframe `df_b`\n",
    "`df_b` has the same column as `df_a` but with other clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:18.393279Z",
     "start_time": "2019-02-18T10:40:18.366265Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': [4, 5, 6, 7, 8],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "df_b = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a third dummy dataframe `df_n`\n",
    "`df_n` has two columns (subject_id, test_id). \n",
    "\n",
    "The column subject_id is common to `df_a`, `df_b` and `df_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:18.685389Z",
     "start_time": "2019-02-18T10:40:18.663131Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': [1, 2, 3, 4, 5, 7, 8, 9, 10, 11],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "df_n = pd.DataFrame(raw_data, columns = ['subject_id','test_id'])\n",
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join `df_a` and `df_b` along raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:19.342148Z",
     "start_time": "2019-02-18T10:40:19.322209Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_a, df_b])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join `df_a` and `df_b` along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:19.894139Z",
     "start_time": "2019-02-18T10:40:19.839009Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df_a, df_b], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes `df_new`, `df_n` using the subject_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:21.251378Z",
     "start_time": "2019-02-18T10:40:21.219190Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_new, df_n, on='subject_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:31:00.552890Z",
     "start_time": "2019-02-18T10:31:00.548221Z"
    }
   },
   "source": [
    "### Merge two dataframes with the left on subject_id and the right on subject_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:40:22.595168Z",
     "start_time": "2019-02-18T10:40:22.567499Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_new, df_n, left_on='subject_id', right_on='test_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with outer join\n",
    "\n",
    "\"Full outer join produces the set of all records in Table A and Table B,\n",
    "with matching records from both sides where available. \n",
    "If there is no match, the missing side will contain null.\"\n",
    "\n",
    "SQL Reference:\n",
    "\n",
    "https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:42:56.691173Z",
     "start_time": "2019-02-18T10:42:56.637734Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:43:27.269325Z",
     "start_time": "2019-02-18T10:43:27.248065Z"
    }
   },
   "source": [
    "### Merge with inner join\n",
    "\n",
    "\"Inner join produces only the set of records that match in both Table A and Table B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:43:39.485860Z",
     "start_time": "2019-02-18T10:43:39.455512Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:44:35.992050Z",
     "start_time": "2019-02-18T10:44:35.978715Z"
    }
   },
   "source": [
    "### Merge with left join\n",
    "\n",
    "\"Left outer join produces a complete set of records from Table A, \n",
    "with the matching records (where available) in Table B. \n",
    "If there is no match, the right side will contain null.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:44:47.241855Z",
     "start_time": "2019-02-18T10:44:47.212413Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_x` and `_y` suffix are sometimes not wanted, the next option helps handles those suffix more clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:44:59.706685Z",
     "start_time": "2019-02-18T10:44:59.699333Z"
    }
   },
   "source": [
    "### Merge while adding a suffix to duplicate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:45:17.366596Z",
     "start_time": "2019-02-18T10:45:17.335772Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='left', suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge based on indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T10:47:17.968598Z",
     "start_time": "2019-02-18T10:47:17.939748Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Merge the datasets :\n",
    "\n",
    "1. car_2017_encoding_latin-1.csv\n",
    "2. car_2018.csv\n",
    "3. claim_2017.csv \n",
    "4. claim_2018_delimiter_semicol.csv\n",
    "5. client_2017.csv\n",
    "6. client_2018.csv\n",
    "\n",
    "You should form one dataset will all the information on the accounts with `ID` as merging column.\n",
    "\n",
    "At each step check the name of the columns and the number of line of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "1. The standard encoding for csv files is `utf-8`, but many database in western Europe use latin-1 encoding.\n",
    "The file `car_2017_format_latin-1.csv` is encoded in the latin-1 format. It must be converted when read.\n",
    "\n",
    "2. The standard delimiter for a csv file in the coma `,`. \n",
    "The file `claim_2018_delimiter_semicol.csv` has a semicolumn delimiter `;`. It must be converted when read.\n",
    "\n",
    "\n",
    "NB: CSV stands for 'coma separater values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T11:13:42.460047Z",
     "start_time": "2019-02-18T11:13:42.454747Z"
    }
   },
   "source": [
    "## Hint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the pandas functions:\n",
    "1. read_csv:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n",
    "Make sure that you understand the `delimiter` and `encoding` option.\n",
    "\n",
    "2. shape:\n",
    "https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.shape.html\n",
    "3. columns:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html\n",
    "4. size:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.size.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "254px",
    "width": "311px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
